{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1、流式输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.messages import SystemMessage, HumanMessage, AIMessage\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "llm = init_chat_model(\n",
    "    model=\"google_genai:gemini-2.5-flash-lite\",\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"你是一名数学家\"),\n",
    "    HumanMessage(content=\"请证明以下黎曼猜想\"),\n",
    "]\n",
    "num = 0\n",
    "# 使用 stream() 方法流式输出\n",
    "for chunk in llm.stream(messages):\n",
    "    num+=1\n",
    "    # 逐个打印内容块，并刷新缓冲区以即时显示内容\n",
    "    print(f'{num}、', chunk.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2、批量回答生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AIMessage(content='春风轻拂过，融化了冰雪，\\n大地苏醒，万物皆有情。\\n嫩芽探出头，好奇地张望，\\n花儿绽笑颜，点缀着山川。\\n\\n燕子衔泥归，筑巢在屋檐，\\n孩童放纸鸢，笑语满庭院。\\n溪水潺潺流，唱着春的歌，\\n阳光暖洋洋，洒满了心田。\\n\\n春天是希望，是新的开始，\\n生命的力量，在悄然萌发。\\n让我们拥抱，这美好的季节，\\n感受春的诗意，绽放生命的华。', additional_kwargs={}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash-lite', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019bd53a-b52c-79b3-8d7b-e28b7591be64-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 11, 'output_tokens': 138, 'total_tokens': 149, 'input_token_details': {'cache_read': 0}}), AIMessage(content='好的，请欣赏这首关于冬天的诗：\\n\\n**冬日絮语**\\n\\n寒风如刀，割裂了天空的蓝，\\n落叶已尽，只剩下光秃的枝干。\\n世界沉睡，披上洁白的衣裳，\\n寂静无声，是大地最深的歌唱。\\n\\n阳光稀薄，却也温暖得难得，\\n映照着冰晶，闪烁着晶莹的梦。\\n炉火跳跃，驱散了彻骨的寒，\\n一杯热茶，温暖了漂泊的心湾。\\n\\n雪花飘落，轻柔地吻着脸庞，\\n堆积成山，覆盖了往日的忧伤。\\n孩子们嬉戏，笑声打破了宁静，\\n在雪地里，留下纯真的脚印。\\n\\n冬日肃穆，孕育着春的希望，\\n万物敛藏，等待着崭新的生长。\\n在这寂寥里，感受生命的沉淀，\\n收藏一份静美，待来年花开烂漫。', additional_kwargs={}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash-lite', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019bd53a-b52c-79b3-8d7b-e29caf0447a3-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 11, 'output_tokens': 224, 'total_tokens': 235, 'input_token_details': {'cache_read': 0}})]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.messages import SystemMessage, HumanMessage, AIMessage\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "llm = init_chat_model(\n",
    "    model=\"google_genai:gemini-2.5-flash-lite\",\n",
    ")\n",
    "# 批量消息列表\n",
    "messages = [\n",
    "    [\n",
    "      SystemMessage(content=\"你是一位诗人\"),\n",
    "      HumanMessage(content=\"写一首关于春天的诗\"),\n",
    "    ],\n",
    "    [\n",
    "      SystemMessage(content=\"你是一位诗人\"),\n",
    "      HumanMessage(content=\"写一首关于冬天的诗\"),\n",
    "    ],\n",
    "]\n",
    "\n",
    "resp = llm.batch(messages) # 批量调用,返回一个消息列表\n",
    "print(resp) # [AIMessage(content='',additional_kwargs={},response_metadata={},id='',tool_calls=[],invalid_tool_calls=[],usage_metadata={}), AIMessage()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3、同步/异步调用，之前的 invoke  就是同步，以下是异步"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-->resps: [AIMessage(content='春风轻拂柳丝柔，\\n桃花点点笑靥羞。\\n燕子归来衔泥忙，\\n莺歌婉转报新愁。\\n\\n冰雪消融溪水唱，\\n嫩芽初绽绿满畴。\\n农人荷锄耕耘早，\\n播下希望待丰收。\\n\\n孩童纸鸢漫天舞，\\n笑语欢声乐无忧。\\n春光无限好时节，\\n万物复苏竞风流。', additional_kwargs={}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash-lite', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019bd54d-31d7-7961-abdf-7e5c0dbe90c0-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 11, 'output_tokens': 104, 'total_tokens': 115, 'input_token_details': {'cache_read': 0}}), AIMessage(content='好的，这是一首关于冬天的诗：\\n\\n**寂静的白**\\n\\n天空垂下灰色的幕，\\n没有一丝云的起伏。\\n风，像个沉默的旅人，\\n吹过光秃的枝桠，低声吟。\\n\\n雪，悄然降临，无声的吻，\\n覆盖了大地，温柔而虔诚。\\n世界褪去了喧嚣的颜色，\\n只剩下纯净，无瑕的辽阔。\\n\\n枯草在雪下安睡，\\n等待春的唤醒，不曾疲惫。\\n冻结的溪流，藏着故事，\\n静静地等待，解冻的时日。\\n\\n阳光，偶尔穿透薄雾，\\n洒下清冷的光，短暂的慰藉。\\n万物沉寂，蓄积着力量，\\n在寒冷中，孕育着希望。\\n\\n炉火跳跃，温暖的火焰，\\n驱散了窗外的凛冽，驱散了孤单。\\n一杯热茶，几许闲愁，\\n冬日的情绪，在心中悠游。\\n\\n这是寂静的季节，\\n也是沉思的时刻。\\n在白色的画布上，\\n描绘着生命的静默与坚韧。', additional_kwargs={}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash-lite', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019bd54d-31d8-77f0-ae92-d127d1352f02-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 11, 'output_tokens': 263, 'total_tokens': 274, 'input_token_details': {'cache_read': 0}})]\n",
      "Total time: 2.134592056274414\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import asyncio\n",
    "import os\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.messages import SystemMessage, HumanMessage, AIMessage\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "llm = init_chat_model(\n",
    "    model=\"google_genai:gemini-2.5-flash-lite\",\n",
    ")\n",
    "# 批量消息列表\n",
    "messagess = [\n",
    "    [\n",
    "      SystemMessage(content=\"你是一位诗人\"),\n",
    "      HumanMessage(content=\"写一首关于春天的诗\"),\n",
    "    ],\n",
    "    [\n",
    "      SystemMessage(content=\"你是一位诗人\"),\n",
    "      HumanMessage(content=\"写一首关于冬天的诗\"),\n",
    "    ],\n",
    "]\n",
    "async def async_invoke():\n",
    "  tasks = [llm.ainvoke(messages) for messages in messagess]\n",
    "  return await asyncio.gather(*tasks)\n",
    "\n",
    "start_time = time.time()\n",
    "# resps = await asyncio.run(async_invoke()) # 报错，不能在已运行的事件循环中使用 asyncio.run()\n",
    "resps = await async_invoke()\n",
    "print('-->resps:',resps)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Total time: {end_time - start_time}\") # 2s左右"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchainlearn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
